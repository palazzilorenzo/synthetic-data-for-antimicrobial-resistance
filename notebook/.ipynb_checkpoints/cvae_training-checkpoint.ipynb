{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a93142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 11:10:57.660437: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from docs.create_cvae import Cvae\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a9ea9",
   "metadata": {},
   "source": [
    "- Split dataset into train and test and save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8d967a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>2000</th>\n",
       "      <th>2003</th>\n",
       "      <th>2006</th>\n",
       "      <th>2009</th>\n",
       "      <th>2012</th>\n",
       "      <th>2015</th>\n",
       "      <th>2018</th>\n",
       "      <th>2021</th>\n",
       "      <th>2024</th>\n",
       "      <th>...</th>\n",
       "      <th>19973</th>\n",
       "      <th>19976</th>\n",
       "      <th>19979</th>\n",
       "      <th>19982</th>\n",
       "      <th>19985</th>\n",
       "      <th>19988</th>\n",
       "      <th>19991</th>\n",
       "      <th>19994</th>\n",
       "      <th>19997</th>\n",
       "      <th>Ampicillin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dad6d494-9432-407e-a03e-fdac7a2739a1</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>3.801878e-08</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>617f14d0-86b1-4c28-8995-b02006a85e81</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.374761e-05</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d5bb4389-5053-4107-9c05-bfed9e9159c9</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>3.647760e-05</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fd880c7e-5f0c-4870-a124-19be1d474d1e</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.592923e-05</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0527af15-2d0f-4e8b-b49f-ef0232db70a0</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>9.404278e-06</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Unnamed: 0      2000      2003      2006  \\\n",
       "0  dad6d494-9432-407e-a03e-fdac7a2739a1  0.000440  0.000482  0.000417   \n",
       "1  617f14d0-86b1-4c28-8995-b02006a85e81  0.000681  0.000405  0.000159   \n",
       "2  d5bb4389-5053-4107-9c05-bfed9e9159c9  0.000270  0.000194  0.000124   \n",
       "3  fd880c7e-5f0c-4870-a124-19be1d474d1e  0.001685  0.001845  0.001435   \n",
       "4  0527af15-2d0f-4e8b-b49f-ef0232db70a0  0.000280  0.000225  0.000297   \n",
       "\n",
       "       2009      2012      2015      2018      2021      2024  ...     19973  \\\n",
       "0  0.000386  0.000244  0.000159  0.000017  0.000139  0.000563  ...  0.000052   \n",
       "1  0.000266  0.000248  0.000213  0.000151  0.000068  0.000751  ...  0.000013   \n",
       "2  0.000156  0.000250  0.000275  0.000088  0.000047  0.000201  ...  0.000019   \n",
       "3  0.001704  0.001408  0.000919  0.000734  0.000556  0.000646  ...  0.000014   \n",
       "4  0.000479  0.000393  0.000397  0.000629  0.000334  0.000076  ...  0.000023   \n",
       "\n",
       "      19976     19979     19982         19985     19988     19991     19994  \\\n",
       "0  0.000056  0.000025  0.000014  3.801878e-08  0.000014  0.000020  0.000029   \n",
       "1  0.000007  0.000003  0.000005  1.374761e-05  0.000025  0.000050  0.000037   \n",
       "2  0.000020  0.000024  0.000022  3.647760e-05  0.000028  0.000023  0.000028   \n",
       "3  0.000020  0.000015  0.000015  1.592923e-05  0.000024  0.000007  0.000009   \n",
       "4  0.000020  0.000019  0.000010  9.404278e-06  0.000007  0.000016  0.000023   \n",
       "\n",
       "      19997  Ampicillin  \n",
       "0  0.000027           R  \n",
       "1  0.000035           R  \n",
       "2  0.000007           S  \n",
       "3  0.000011           R  \n",
       "4  0.000024           S  \n",
       "\n",
       "[5 rows x 6002 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data (Escherichia coli spectra) into dataframe with Pandas\n",
    "\n",
    "path_to_data = '../CVAE/real_data/Escherichia_coli_CVAE.txt'\n",
    "\n",
    "df = pd.read_csv(path_to_data, sep='\\t', header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d313562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>2003</th>\n",
       "      <th>2006</th>\n",
       "      <th>2009</th>\n",
       "      <th>2012</th>\n",
       "      <th>2015</th>\n",
       "      <th>2018</th>\n",
       "      <th>2021</th>\n",
       "      <th>2024</th>\n",
       "      <th>2027</th>\n",
       "      <th>...</th>\n",
       "      <th>19973</th>\n",
       "      <th>19976</th>\n",
       "      <th>19979</th>\n",
       "      <th>19982</th>\n",
       "      <th>19985</th>\n",
       "      <th>19988</th>\n",
       "      <th>19991</th>\n",
       "      <th>19994</th>\n",
       "      <th>19997</th>\n",
       "      <th>Ampicillin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>3.801878e-08</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.374761e-05</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>3.647760e-05</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.592923e-05</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>9.404278e-06</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       2000      2003      2006      2009      2012      2015      2018  \\\n",
       "0  0.000440  0.000482  0.000417  0.000386  0.000244  0.000159  0.000017   \n",
       "1  0.000681  0.000405  0.000159  0.000266  0.000248  0.000213  0.000151   \n",
       "2  0.000270  0.000194  0.000124  0.000156  0.000250  0.000275  0.000088   \n",
       "3  0.001685  0.001845  0.001435  0.001704  0.001408  0.000919  0.000734   \n",
       "4  0.000280  0.000225  0.000297  0.000479  0.000393  0.000397  0.000629   \n",
       "\n",
       "       2021      2024      2027  ...     19973     19976     19979     19982  \\\n",
       "0  0.000139  0.000563  0.000477  ...  0.000052  0.000056  0.000025  0.000014   \n",
       "1  0.000068  0.000751  0.001529  ...  0.000013  0.000007  0.000003  0.000005   \n",
       "2  0.000047  0.000201  0.000245  ...  0.000019  0.000020  0.000024  0.000022   \n",
       "3  0.000556  0.000646  0.000707  ...  0.000014  0.000020  0.000015  0.000015   \n",
       "4  0.000334  0.000076  0.000092  ...  0.000023  0.000020  0.000019  0.000010   \n",
       "\n",
       "          19985     19988     19991     19994     19997  Ampicillin  \n",
       "0  3.801878e-08  0.000014  0.000020  0.000029  0.000027           0  \n",
       "1  1.374761e-05  0.000025  0.000050  0.000037  0.000035           0  \n",
       "2  3.647760e-05  0.000028  0.000023  0.000028  0.000007           1  \n",
       "3  1.592923e-05  0.000024  0.000007  0.000009  0.000011           0  \n",
       "4  9.404278e-06  0.000007  0.000016  0.000023  0.000024           1  \n",
       "\n",
       "[5 rows x 6001 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the 'Unnamed: 0' column to select only the intensity values and susceptibility\n",
    "df = df.drop(['Unnamed: 0'],  axis = 1)\n",
    "col = df.columns.values.tolist() # get the list of all columns that will be needed later\n",
    "\n",
    "# Replace 'R' and 'S' with 0 and 1\n",
    "df['Ampicillin'] = df['Ampicillin'].replace('R', 0)\n",
    "df['Ampicillin'] = df['Ampicillin'].replace('S', 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3328e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df.drop(['Ampicillin'], axis = 1) # dataframe containing only intensity values\n",
    "df_labels = pd.DataFrame(df['Ampicillin']) # dataframe containing only susceptibility information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dfc089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data, stratifying by label\n",
    "\n",
    "train_x, test_x, train_labels, test_labels = train_test_split(df_X, df_labels,\n",
    "                                                    stratify=df_labels, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# saving as a CSV file\n",
    "train_x.to_csv('../CVAE/real_data/train/Escherichia_coli_CVAE_train_x.csv', sep ='\\t')\n",
    "train_labels.to_csv('../CVAE/real_data/train/Escherichia_coli_CVAE_train_labels.csv', sep ='\\t')\n",
    "test_x.to_csv('../CVAE/real_data/test/Escherichia_coli_CVAE_test_x.csv', sep ='\\t')\n",
    "test_labels.to_csv('../CVAE/real_data/test/Escherichia_coli_CVAE_test_labels.csv', sep ='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9014336e",
   "metadata": {},
   "source": [
    "### Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd153108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training data\n",
    "path_to_train_x = '../CVAE/real_data/train/Escherichia_coli_CVAE_train_x.csv'\n",
    "path_to_train_labels = '../CVAE/real_data/train/Escherichia_coli_CVAE_train_labels.csv'\n",
    "\n",
    "train_x = pd.read_csv(path_to_train_x, sep='\\t', header=0)\n",
    "train_labels = pd.read_csv(path_to_train_labels, sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9698c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.drop(['Unnamed: 0'],  axis = 1)\n",
    "train_labels = train_labels.drop(['Unnamed: 0'],  axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "109c2a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3daabfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create CVAE\n",
    "cvae_64 = Cvae(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5f5a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This callback will stop the training when there is no improvement in\n",
    "# the loss for ten consecutive epochs.\n",
    "\n",
    "callback = EarlyStopping(monitor='loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d2ba043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "27/27 [==============================] - 9s 263ms/step - loss: 2843.5969 - reconstruction_loss: 1380.7286 - kl_loss: 131.2672\n",
      "Epoch 2/120\n",
      "27/27 [==============================] - 7s 273ms/step - loss: 34.1148 - reconstruction_loss: 16.6282 - kl_loss: 13.3957\n",
      "Epoch 3/120\n",
      "27/27 [==============================] - 7s 265ms/step - loss: 26.1339 - reconstruction_loss: 16.0663 - kl_loss: 10.4912\n",
      "Epoch 4/120\n",
      "27/27 [==============================] - 7s 267ms/step - loss: 41.9005 - reconstruction_loss: 27.1158 - kl_loss: 23.0435\n",
      "Epoch 5/120\n",
      "27/27 [==============================] - 7s 261ms/step - loss: 34.0251 - reconstruction_loss: 20.6316 - kl_loss: 15.7840\n",
      "Epoch 6/120\n",
      "27/27 [==============================] - 7s 262ms/step - loss: 23.3003 - reconstruction_loss: 14.0259 - kl_loss: 7.5792\n",
      "Epoch 7/120\n",
      "27/27 [==============================] - 7s 264ms/step - loss: 26.9505 - reconstruction_loss: 26.1237 - kl_loss: 18.5291\n",
      "Epoch 8/120\n",
      "27/27 [==============================] - 7s 262ms/step - loss: 63.8151 - reconstruction_loss: 20.4140 - kl_loss: 22.9748\n",
      "Epoch 9/120\n",
      "27/27 [==============================] - 7s 260ms/step - loss: 23.2642 - reconstruction_loss: 13.3269 - kl_loss: 7.2859\n",
      "Epoch 10/120\n",
      "27/27 [==============================] - 7s 258ms/step - loss: 20.0737 - reconstruction_loss: 14.5202 - kl_loss: 6.7681\n",
      "Epoch 11/120\n",
      "27/27 [==============================] - 7s 263ms/step - loss: 18.6543 - reconstruction_loss: 12.1986 - kl_loss: 4.7907\n",
      "Epoch 12/120\n",
      "27/27 [==============================] - 7s 270ms/step - loss: 17.8016 - reconstruction_loss: 12.7722 - kl_loss: 4.7105\n",
      "Epoch 13/120\n",
      "27/27 [==============================] - 7s 264ms/step - loss: 15.5364 - reconstruction_loss: 11.7323 - kl_loss: 3.4904\n",
      "Epoch 14/120\n",
      "27/27 [==============================] - 7s 271ms/step - loss: 15.8676 - reconstruction_loss: 11.6416 - kl_loss: 3.5816\n",
      "Epoch 15/120\n",
      "27/27 [==============================] - 7s 268ms/step - loss: 13.9516 - reconstruction_loss: 11.2045 - kl_loss: 2.5626\n",
      "Epoch 16/120\n",
      "27/27 [==============================] - 7s 266ms/step - loss: 15.2618 - reconstruction_loss: 12.3773 - kl_loss: 3.4766\n",
      "Epoch 17/120\n",
      "27/27 [==============================] - 7s 267ms/step - loss: 18.7324 - reconstruction_loss: 12.6067 - kl_loss: 4.9010\n",
      "Epoch 18/120\n",
      "27/27 [==============================] - 7s 264ms/step - loss: 16.6902 - reconstruction_loss: 11.4884 - kl_loss: 3.0979\n",
      "Epoch 19/120\n",
      "27/27 [==============================] - 8s 277ms/step - loss: 13.2447 - reconstruction_loss: 10.8800 - kl_loss: 2.1481\n",
      "Epoch 20/120\n",
      "27/27 [==============================] - 7s 269ms/step - loss: 13.0340 - reconstruction_loss: 11.2529 - kl_loss: 2.1012\n",
      "Epoch 21/120\n",
      "27/27 [==============================] - 7s 276ms/step - loss: 12.7348 - reconstruction_loss: 10.4334 - kl_loss: 1.6997\n",
      "Epoch 22/120\n",
      "27/27 [==============================] - 7s 269ms/step - loss: 12.8771 - reconstruction_loss: 11.6659 - kl_loss: 1.5220\n",
      "Epoch 23/120\n",
      "27/27 [==============================] - 7s 268ms/step - loss: 12.2805 - reconstruction_loss: 10.0760 - kl_loss: 1.7289\n",
      "Epoch 24/120\n",
      "27/27 [==============================] - 7s 266ms/step - loss: 11.7992 - reconstruction_loss: 10.4158 - kl_loss: 0.8337\n",
      "Epoch 25/120\n",
      "27/27 [==============================] - 7s 263ms/step - loss: 10.4628 - reconstruction_loss: 9.6409 - kl_loss: 0.6242\n",
      "Epoch 26/120\n",
      "27/27 [==============================] - 7s 267ms/step - loss: 10.5394 - reconstruction_loss: 9.9651 - kl_loss: 0.4620\n",
      "Epoch 27/120\n",
      "27/27 [==============================] - 7s 265ms/step - loss: 9.7579 - reconstruction_loss: 9.4086 - kl_loss: 0.3510\n",
      "Epoch 28/120\n",
      "27/27 [==============================] - 7s 265ms/step - loss: 9.6016 - reconstruction_loss: 9.5010 - kl_loss: 0.2521\n",
      "Epoch 29/120\n",
      "27/27 [==============================] - 7s 266ms/step - loss: 9.4955 - reconstruction_loss: 9.2775 - kl_loss: 0.1891\n",
      "Epoch 30/120\n",
      "27/27 [==============================] - 7s 265ms/step - loss: 9.3135 - reconstruction_loss: 9.1588 - kl_loss: 0.1597\n",
      "Epoch 31/120\n",
      "27/27 [==============================] - 7s 266ms/step - loss: 9.2983 - reconstruction_loss: 9.2341 - kl_loss: 0.0889\n",
      "Epoch 32/120\n",
      "27/27 [==============================] - 7s 267ms/step - loss: 9.1332 - reconstruction_loss: 9.0933 - kl_loss: 0.0738\n",
      "Epoch 33/120\n",
      "27/27 [==============================] - 7s 262ms/step - loss: 9.1057 - reconstruction_loss: 9.0285 - kl_loss: 0.0717\n",
      "Epoch 34/120\n",
      "27/27 [==============================] - 7s 277ms/step - loss: 9.0459 - reconstruction_loss: 9.0119 - kl_loss: 0.0695\n",
      "Epoch 35/120\n",
      "27/27 [==============================] - 7s 265ms/step - loss: 9.0539 - reconstruction_loss: 8.9943 - kl_loss: 0.0674\n",
      "Epoch 36/120\n",
      "27/27 [==============================] - 7s 262ms/step - loss: 9.0184 - reconstruction_loss: 8.9572 - kl_loss: 0.0653\n",
      "Epoch 37/120\n",
      "27/27 [==============================] - 7s 266ms/step - loss: 8.9635 - reconstruction_loss: 8.9271 - kl_loss: 0.0632\n",
      "Epoch 38/120\n",
      "27/27 [==============================] - 7s 270ms/step - loss: 8.9502 - reconstruction_loss: 8.9362 - kl_loss: 0.0612\n",
      "Epoch 39/120\n",
      "27/27 [==============================] - 7s 264ms/step - loss: 9.0122 - reconstruction_loss: 8.9237 - kl_loss: 0.0594\n",
      "Epoch 40/120\n",
      "27/27 [==============================] - 7s 264ms/step - loss: 8.9767 - reconstruction_loss: 8.9141 - kl_loss: 0.0576\n",
      "Epoch 41/120\n",
      "27/27 [==============================] - 7s 260ms/step - loss: 8.9230 - reconstruction_loss: 8.8915 - kl_loss: 0.0557\n",
      "Epoch 42/120\n",
      "27/27 [==============================] - 7s 260ms/step - loss: 9.0157 - reconstruction_loss: 8.8879 - kl_loss: 0.0540\n",
      "Epoch 43/120\n",
      "27/27 [==============================] - 7s 261ms/step - loss: 8.8999 - reconstruction_loss: 8.8546 - kl_loss: 0.0523\n",
      "Epoch 44/120\n",
      "27/27 [==============================] - 7s 263ms/step - loss: 8.8910 - reconstruction_loss: 8.8407 - kl_loss: 0.0506\n",
      "Epoch 45/120\n",
      "27/27 [==============================] - 7s 264ms/step - loss: 8.8968 - reconstruction_loss: 8.8385 - kl_loss: 0.0491\n",
      "Epoch 46/120\n",
      "27/27 [==============================] - 7s 263ms/step - loss: 8.9115 - reconstruction_loss: 8.8524 - kl_loss: 0.0476\n",
      "Epoch 47/120\n",
      "27/27 [==============================] - 7s 261ms/step - loss: 8.9411 - reconstruction_loss: 8.8514 - kl_loss: 0.0462\n",
      "Epoch 48/120\n",
      "27/27 [==============================] - 7s 263ms/step - loss: 8.8878 - reconstruction_loss: 8.8475 - kl_loss: 0.0447\n",
      "Epoch 49/120\n",
      "27/27 [==============================] - 7s 267ms/step - loss: 8.9095 - reconstruction_loss: 8.8555 - kl_loss: 0.0434\n",
      "Epoch 50/120\n",
      "27/27 [==============================] - 7s 266ms/step - loss: 8.8776 - reconstruction_loss: 8.8321 - kl_loss: 0.0420\n",
      "Epoch 51/120\n",
      "27/27 [==============================] - 7s 264ms/step - loss: 8.8898 - reconstruction_loss: 8.8503 - kl_loss: 0.0407\n",
      "Epoch 52/120\n",
      "27/27 [==============================] - 7s 263ms/step - loss: 8.8362 - reconstruction_loss: 8.8300 - kl_loss: 0.0394\n",
      "Epoch 53/120\n",
      "27/27 [==============================] - 7s 262ms/step - loss: 8.8541 - reconstruction_loss: 8.8113 - kl_loss: 0.0382\n",
      "Epoch 54/120\n",
      "27/27 [==============================] - 7s 267ms/step - loss: 8.8342 - reconstruction_loss: 8.8109 - kl_loss: 0.0369\n",
      "Epoch 55/120\n",
      "27/27 [==============================] - 7s 261ms/step - loss: 8.8262 - reconstruction_loss: 8.8048 - kl_loss: 0.0357\n",
      "Epoch 56/120\n",
      "27/27 [==============================] - 7s 261ms/step - loss: 8.8612 - reconstruction_loss: 8.8168 - kl_loss: 0.0346\n",
      "Epoch 57/120\n",
      "27/27 [==============================] - 7s 259ms/step - loss: 8.8711 - reconstruction_loss: 8.8175 - kl_loss: 0.0335\n",
      "Epoch 58/120\n",
      "27/27 [==============================] - 7s 261ms/step - loss: 8.8228 - reconstruction_loss: 8.7937 - kl_loss: 0.0324\n",
      "Epoch 59/120\n",
      "27/27 [==============================] - 7s 260ms/step - loss: 8.8227 - reconstruction_loss: 8.7939 - kl_loss: 0.0314\n",
      "Epoch 60/120\n",
      "27/27 [==============================] - 7s 273ms/step - loss: 8.8422 - reconstruction_loss: 8.7979 - kl_loss: 0.0304\n",
      "Epoch 61/120\n",
      "27/27 [==============================] - 7s 272ms/step - loss: 8.8244 - reconstruction_loss: 8.8085 - kl_loss: 0.0294\n",
      "Epoch 62/120\n",
      "27/27 [==============================] - 7s 271ms/step - loss: 8.7907 - reconstruction_loss: 8.7918 - kl_loss: 0.0284\n",
      "Epoch 63/120\n",
      "27/27 [==============================] - 7s 260ms/step - loss: 8.8169 - reconstruction_loss: 8.7911 - kl_loss: 0.0275\n",
      "Epoch 64/120\n",
      "27/27 [==============================] - 7s 260ms/step - loss: 8.8584 - reconstruction_loss: 8.8051 - kl_loss: 0.0265\n",
      "Epoch 65/120\n",
      "27/27 [==============================] - 7s 266ms/step - loss: 8.8467 - reconstruction_loss: 8.7940 - kl_loss: 0.0256\n",
      "Epoch 66/120\n",
      "27/27 [==============================] - 7s 265ms/step - loss: 8.8248 - reconstruction_loss: 8.7846 - kl_loss: 0.0248\n",
      "Epoch 67/120\n",
      "27/27 [==============================] - 7s 265ms/step - loss: 8.8641 - reconstruction_loss: 8.7890 - kl_loss: 0.0239\n",
      "Epoch 68/120\n",
      "27/27 [==============================] - 7s 266ms/step - loss: 8.8368 - reconstruction_loss: 8.7844 - kl_loss: 0.0231\n",
      "Epoch 69/120\n",
      "27/27 [==============================] - 7s 264ms/step - loss: 8.8053 - reconstruction_loss: 8.8098 - kl_loss: 0.0223\n",
      "Epoch 70/120\n",
      "27/27 [==============================] - 7s 264ms/step - loss: 8.8138 - reconstruction_loss: 8.7968 - kl_loss: 0.0216\n",
      "Epoch 71/120\n",
      "27/27 [==============================] - 7s 271ms/step - loss: 8.7915 - reconstruction_loss: 8.7841 - kl_loss: 0.0209\n",
      "Epoch 72/120\n",
      "27/27 [==============================] - 7s 269ms/step - loss: 8.8099 - reconstruction_loss: 8.7822 - kl_loss: 0.0201\n",
      "Epoch 73/120\n",
      "27/27 [==============================] - 8s 312ms/step - loss: 8.8228 - reconstruction_loss: 8.7770 - kl_loss: 0.0194\n",
      "Epoch 74/120\n",
      "27/27 [==============================] - 7s 274ms/step - loss: 8.7744 - reconstruction_loss: 8.7889 - kl_loss: 0.0187\n",
      "Epoch 75/120\n",
      "27/27 [==============================] - 7s 270ms/step - loss: 8.8325 - reconstruction_loss: 8.7898 - kl_loss: 0.0180\n",
      "Epoch 76/120\n",
      "27/27 [==============================] - 7s 267ms/step - loss: 8.7939 - reconstruction_loss: 8.7813 - kl_loss: 0.0173\n",
      "Epoch 77/120\n",
      "27/27 [==============================] - 7s 269ms/step - loss: 8.8116 - reconstruction_loss: 8.7863 - kl_loss: 0.0167\n",
      "Epoch 78/120\n",
      "27/27 [==============================] - 7s 267ms/step - loss: 8.8155 - reconstruction_loss: 8.7908 - kl_loss: 0.0161\n",
      "Epoch 79/120\n",
      "27/27 [==============================] - 7s 270ms/step - loss: 8.8093 - reconstruction_loss: 8.7923 - kl_loss: 0.0155\n",
      "Epoch 80/120\n",
      "27/27 [==============================] - 7s 267ms/step - loss: 8.7815 - reconstruction_loss: 8.7859 - kl_loss: 0.0150\n",
      "Epoch 81/120\n",
      "27/27 [==============================] - 7s 268ms/step - loss: 8.7733 - reconstruction_loss: 8.7898 - kl_loss: 0.0144\n",
      "Epoch 82/120\n",
      "27/27 [==============================] - 7s 269ms/step - loss: 8.8036 - reconstruction_loss: 8.7833 - kl_loss: 0.0139\n",
      "Epoch 83/120\n",
      "27/27 [==============================] - 8s 279ms/step - loss: 8.8073 - reconstruction_loss: 8.7799 - kl_loss: 0.0133\n",
      "Epoch 84/120\n",
      "27/27 [==============================] - 7s 272ms/step - loss: 8.8168 - reconstruction_loss: 8.7851 - kl_loss: 0.0128\n",
      "Epoch 85/120\n",
      "27/27 [==============================] - 7s 267ms/step - loss: 8.8005 - reconstruction_loss: 8.7847 - kl_loss: 0.0124\n",
      "Epoch 86/120\n",
      "27/27 [==============================] - 7s 269ms/step - loss: 8.7809 - reconstruction_loss: 8.7768 - kl_loss: 0.0119\n",
      "Epoch 87/120\n",
      "27/27 [==============================] - 7s 277ms/step - loss: 8.7942 - reconstruction_loss: 8.7794 - kl_loss: 0.0114\n",
      "Epoch 88/120\n",
      "27/27 [==============================] - 7s 269ms/step - loss: 8.7869 - reconstruction_loss: 8.7813 - kl_loss: 0.0110\n",
      "Epoch 89/120\n",
      "27/27 [==============================] - 7s 266ms/step - loss: 8.7458 - reconstruction_loss: 8.7715 - kl_loss: 0.0105\n",
      "Epoch 90/120\n",
      "27/27 [==============================] - 7s 268ms/step - loss: 8.7820 - reconstruction_loss: 8.7770 - kl_loss: 0.0101\n",
      "Epoch 91/120\n",
      "27/27 [==============================] - 7s 269ms/step - loss: 8.7556 - reconstruction_loss: 8.7716 - kl_loss: 0.0097\n",
      "Epoch 92/120\n",
      "27/27 [==============================] - 7s 266ms/step - loss: 8.7670 - reconstruction_loss: 8.7712 - kl_loss: 0.0093\n",
      "Epoch 93/120\n",
      "27/27 [==============================] - 7s 270ms/step - loss: 8.7602 - reconstruction_loss: 8.7737 - kl_loss: 0.0089\n",
      "Epoch 94/120\n",
      "27/27 [==============================] - 7s 271ms/step - loss: 8.7774 - reconstruction_loss: 8.7582 - kl_loss: 0.0085\n",
      "Epoch 95/120\n",
      "27/27 [==============================] - 7s 274ms/step - loss: 8.7723 - reconstruction_loss: 8.7562 - kl_loss: 0.0082\n",
      "Epoch 96/120\n",
      "27/27 [==============================] - 7s 269ms/step - loss: 8.7656 - reconstruction_loss: 8.7815 - kl_loss: 0.0078\n",
      "Epoch 97/120\n",
      "27/27 [==============================] - 7s 268ms/step - loss: 8.7912 - reconstruction_loss: 8.7772 - kl_loss: 0.0075\n",
      "Epoch 98/120\n",
      "27/27 [==============================] - 7s 271ms/step - loss: 8.7821 - reconstruction_loss: 8.7533 - kl_loss: 0.0072\n",
      "Epoch 99/120\n",
      "27/27 [==============================] - 7s 268ms/step - loss: 8.7744 - reconstruction_loss: 8.7719 - kl_loss: 0.0069\n",
      "Epoch 100/120\n",
      "27/27 [==============================] - 7s 271ms/step - loss: 8.7549 - reconstruction_loss: 8.7610 - kl_loss: 0.0066\n",
      "Epoch 101/120\n",
      "27/27 [==============================] - 7s 273ms/step - loss: 8.7731 - reconstruction_loss: 8.7672 - kl_loss: 0.0063\n",
      "Epoch 102/120\n",
      "27/27 [==============================] - 7s 268ms/step - loss: 8.7693 - reconstruction_loss: 8.7691 - kl_loss: 0.0060\n",
      "Epoch 103/120\n",
      "27/27 [==============================] - 7s 267ms/step - loss: 8.7646 - reconstruction_loss: 8.7584 - kl_loss: 0.0057\n",
      "Epoch 104/120\n",
      "27/27 [==============================] - 8s 280ms/step - loss: 8.7654 - reconstruction_loss: 8.7671 - kl_loss: 0.0055\n",
      "Epoch 105/120\n",
      "27/27 [==============================] - 7s 275ms/step - loss: 8.7592 - reconstruction_loss: 8.7666 - kl_loss: 0.0052\n",
      "Epoch 106/120\n",
      "27/27 [==============================] - 9s 345ms/step - loss: 8.7755 - reconstruction_loss: 8.7599 - kl_loss: 0.0050\n",
      "Epoch 107/120\n",
      "27/27 [==============================] - 8s 302ms/step - loss: 8.7374 - reconstruction_loss: 8.7597 - kl_loss: 0.0048\n",
      "Epoch 108/120\n",
      "27/27 [==============================] - 7s 264ms/step - loss: 8.7614 - reconstruction_loss: 8.7714 - kl_loss: 0.0045\n",
      "Number of epochs run 108\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# save history on file\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../CVAE/history/history_cvae_64.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 9\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(history_2\u001b[38;5;241m.\u001b[39mhistory, f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "# fit\n",
    "history_64 = cvae_64.fit(train_x, train_labels, batch_size=6, epochs=120, callbacks=[callback])\n",
    "print(\"Number of epochs run\", len(history_64.history['loss']))\n",
    "\n",
    "# save weights\n",
    "cvae_64.save_weights('../CVAE/weights/cvae_64_weights.h5')\n",
    "# save history on file\n",
    "with open('../CVAE/history/history_cvae_64.json', 'w') as f:\n",
    "    json.dump(history_64.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e89289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
